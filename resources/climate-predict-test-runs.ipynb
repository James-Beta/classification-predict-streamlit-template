{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:47:34.906449Z",
     "iopub.status.busy": "2022-06-22T09:47:34.905782Z",
     "iopub.status.idle": "2022-06-22T09:47:34.944318Z",
     "shell.execute_reply": "2022-06-22T09:47:34.943122Z",
     "shell.execute_reply.started": "2022-06-22T09:47:34.906315Z"
    }
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:47:44.292952Z",
     "iopub.status.busy": "2022-06-22T09:47:44.292476Z",
     "iopub.status.idle": "2022-06-22T09:47:45.145298Z",
     "shell.execute_reply": "2022-06-22T09:47:45.14438Z",
     "shell.execute_reply.started": "2022-06-22T09:47:44.292917Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Importing preprocessing modules\n",
    "!pip install nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Importing model building modules\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "\n",
    "#Importing modules for scoring \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:47:59.296502Z",
     "iopub.status.busy": "2022-06-22T09:47:59.296074Z",
     "iopub.status.idle": "2022-06-22T09:47:59.42979Z",
     "shell.execute_reply": "2022-06-22T09:47:59.428679Z",
     "shell.execute_reply.started": "2022-06-22T09:47:59.296462Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:06.541531Z",
     "iopub.status.busy": "2022-06-20T23:27:06.541124Z",
     "iopub.status.idle": "2022-06-20T23:27:06.569857Z",
     "shell.execute_reply": "2022-06-20T23:27:06.568796Z",
     "shell.execute_reply.started": "2022-06-20T23:27:06.541482Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:06.573057Z",
     "iopub.status.busy": "2022-06-20T23:27:06.572271Z",
     "iopub.status.idle": "2022-06-20T23:27:06.580541Z",
     "shell.execute_reply": "2022-06-20T23:27:06.579561Z",
     "shell.execute_reply.started": "2022-06-20T23:27:06.57301Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['message'].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:06.582453Z",
     "iopub.status.busy": "2022-06-20T23:27:06.5817Z",
     "iopub.status.idle": "2022-06-20T23:27:06.592719Z",
     "shell.execute_reply": "2022-06-20T23:27:06.592002Z",
     "shell.execute_reply.started": "2022-06-20T23:27:06.582409Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['tweetid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:06.594644Z",
     "iopub.status.busy": "2022-06-20T23:27:06.594123Z",
     "iopub.status.idle": "2022-06-20T23:27:06.606223Z",
     "shell.execute_reply": "2022-06-20T23:27:06.605252Z",
     "shell.execute_reply.started": "2022-06-20T23:27:06.594612Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:48:02.656825Z",
     "iopub.status.busy": "2022-06-22T09:48:02.655838Z",
     "iopub.status.idle": "2022-06-22T09:48:02.665057Z",
     "shell.execute_reply": "2022-06-22T09:48:02.663515Z",
     "shell.execute_reply.started": "2022-06-22T09:48:02.656787Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_title(title): \n",
    "    \n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+' #Pattern to remove all hyperlinks\n",
    "    title = re.sub(pattern_url,'',title)   #Removing all hyperlinks from statement\n",
    "    #title = re.sub('RT @.*:','',title)    #Removing all preceding RT @ from every post\n",
    "    title = re.sub('@\\w+','',title)  #Removing all  ''@'' twitter handles\n",
    "    #title = re.sub(r'(\\s)#\\w+','',title)  ##Removing  all hashtags\n",
    "    title = re.sub(\"[^a-zA-Z0-9 ]\", \"\", title) #Extracting Remaining text from  \n",
    "    title = re.sub(r'[,!?;-]+', '.', title) #Removing any remaining non-characters\n",
    "    #title = title.replace('RT', '')     #Removing RT{retweet} from posts\n",
    "    title = re.sub('[%s]' % re.escape(string.punctuation), '', title)\n",
    "    title = re.sub('\\w*\\d\\w*', '', title)\n",
    "    title = title.strip().capitalize()   #Removing all remaining whitespaces and Capitalizing all Posts\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:48:06.585363Z",
     "iopub.status.busy": "2022-06-22T09:48:06.584839Z",
     "iopub.status.idle": "2022-06-22T09:48:07.308777Z",
     "shell.execute_reply": "2022-06-22T09:48:07.307555Z",
     "shell.execute_reply.started": "2022-06-22T09:48:06.585325Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['cleaned_message'] = df_train['message'].apply(clean_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:07.047416Z",
     "iopub.status.busy": "2022-06-20T23:27:07.046917Z",
     "iopub.status.idle": "2022-06-20T23:27:07.064365Z",
     "shell.execute_reply": "2022-06-20T23:27:07.063433Z",
     "shell.execute_reply.started": "2022-06-20T23:27:07.047383Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:07.066631Z",
     "iopub.status.busy": "2022-06-20T23:27:07.066227Z",
     "iopub.status.idle": "2022-06-20T23:27:07.074441Z",
     "shell.execute_reply": "2022-06-20T23:27:07.073462Z",
     "shell.execute_reply.started": "2022-06-20T23:27:07.066594Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.cleaned_message.values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:07.076439Z",
     "iopub.status.busy": "2022-06-20T23:27:07.075661Z",
     "iopub.status.idle": "2022-06-20T23:27:07.085895Z",
     "shell.execute_reply": "2022-06-20T23:27:07.08488Z",
     "shell.execute_reply.started": "2022-06-20T23:27:07.076402Z"
    }
   },
   "outputs": [],
   "source": [
    "term = 'RT @pablorodas: #CLIMATEchange #p2 RT  Trump picks climate change sceptic Scott Pruitt to lead EPA https://t.co/1xb8rrW026 #COP22 https://tâ€¦'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:49:01.241736Z",
     "iopub.status.busy": "2022-06-22T09:49:01.240747Z",
     "iopub.status.idle": "2022-06-22T09:49:01.248719Z",
     "shell.execute_reply": "2022-06-22T09:49:01.248015Z",
     "shell.execute_reply.started": "2022-06-22T09:49:01.241686Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to prepare text for modelling\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def model_prep_data(message):\n",
    "    \n",
    "    review = message.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [stemmer.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    #review = [word for word in review if len(word) > 1]\n",
    "    \n",
    "    \n",
    "    return ' '.join(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:49:01.250574Z",
     "iopub.status.busy": "2022-06-22T09:49:01.249958Z",
     "iopub.status.idle": "2022-06-22T09:49:40.05191Z",
     "shell.execute_reply": "2022-06-22T09:49:40.050822Z",
     "shell.execute_reply.started": "2022-06-22T09:49:01.250533Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating new column of prepared data to be used for modelling\n",
    "df_train['model_prep_data'] = df_train['cleaned_message'].apply(model_prep_data)\n",
    "df_train[['cleaned_message','model_prep_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T06:54:34.100177Z",
     "iopub.status.busy": "2022-06-22T06:54:34.099799Z",
     "iopub.status.idle": "2022-06-22T06:54:34.104245Z",
     "shell.execute_reply": "2022-06-22T06:54:34.103368Z",
     "shell.execute_reply.started": "2022-06-22T06:54:34.100139Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Creating the Bag of Words vectorizer\n",
    "# cv = CountVectorizer(stop_words='english', max_features=2500)\n",
    "# X = cv.fit_transform(df_train.model_prep_data).toarray()\n",
    "# data_X =  pd.DataFrame(X, columns=cv.get_feature_names())\n",
    "# data_X.index = df_train.tweetid\n",
    "# data_X = data_X.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:42.970055Z",
     "iopub.status.busy": "2022-06-20T23:27:42.969631Z",
     "iopub.status.idle": "2022-06-20T23:27:42.974208Z",
     "shell.execute_reply": "2022-06-20T23:27:42.973381Z",
     "shell.execute_reply.started": "2022-06-20T23:27:42.970022Z"
    }
   },
   "outputs": [],
   "source": [
    "# top_dict = {}\n",
    "# for c in data_X.columns:\n",
    "#     top = data_X[c].sort_values(ascending=False).head(30)\n",
    "#     top_dict[c]= list(zip(top.index, top.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T04:08:45.244167Z",
     "iopub.status.busy": "2022-06-22T04:08:45.243454Z",
     "iopub.status.idle": "2022-06-22T04:08:45.984567Z",
     "shell.execute_reply": "2022-06-22T04:08:45.983517Z",
     "shell.execute_reply.started": "2022-06-22T04:08:45.244123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the scaler module to scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale data\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:49:40.055724Z",
     "iopub.status.busy": "2022-06-22T09:49:40.054869Z",
     "iopub.status.idle": "2022-06-22T09:49:41.460284Z",
     "shell.execute_reply": "2022-06-22T09:49:41.458837Z",
     "shell.execute_reply.started": "2022-06-22T09:49:40.055672Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a tfidf Vectorizer for modelling\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1,2)\n",
    "                       )\n",
    "# We transform each complaint into a vector\n",
    "features = tfidf.fit_transform(df_train.model_prep_data).toarray()\n",
    "labels = df_train.sentiment\n",
    "model_save_path = \"tfidf.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(tfidf,file)\n",
    "print(\"Each of the %d complaints is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:44.794251Z",
     "iopub.status.busy": "2022-06-20T23:27:44.793569Z",
     "iopub.status.idle": "2022-06-20T23:27:44.798039Z",
     "shell.execute_reply": "2022-06-20T23:27:44.79707Z",
     "shell.execute_reply.started": "2022-06-20T23:27:44.794218Z"
    }
   },
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from collections import Counter\n",
    "\n",
    "\n",
    "# rus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\n",
    "# x_rus, y_rus = rus.fit_resample(features, labels)\n",
    "\n",
    "# print('original dataset shape:', Counter(labels))\n",
    "# print('Resample dataset shape', Counter(y_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:49:41.46275Z",
     "iopub.status.busy": "2022-06-22T09:49:41.462208Z",
     "iopub.status.idle": "2022-06-22T09:49:42.09006Z",
     "shell.execute_reply": "2022-06-22T09:49:42.089137Z",
     "shell.execute_reply.started": "2022-06-22T09:49:41.462702Z"
    }
   },
   "outputs": [],
   "source": [
    "#Splitting dataset into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels,test_size=0.2, random_state = 42)\n",
    "\n",
    "# # Import the var thresh model and choose a threshold\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# selector = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "# # Transform (i.e.: run selection on) the training data\n",
    "# X_train_vt = selector.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T09:50:33.542838Z",
     "iopub.status.busy": "2022-06-22T09:50:33.542289Z",
     "iopub.status.idle": "2022-06-22T11:01:34.38266Z",
     "shell.execute_reply": "2022-06-22T11:01:34.381288Z",
     "shell.execute_reply.started": "2022-06-22T09:50:33.542795Z"
    }
   },
   "outputs": [],
   "source": [
    "#generic function to fit model and return metrics for every algorithm\n",
    "def boost_models(x):\n",
    "    '''\n",
    "    This function receives a model as a parameter, the target for the mordel is then transformed using the quantile transformer \n",
    "    to transform it. The model is then trained and tested and the Test set. The errors and accuraciers are then computed\n",
    "    and returned as a function response\n",
    "    '''\n",
    "    \n",
    "    #Instantiating model to be used\n",
    "    model = x \n",
    "    algoname= x.__class__.__name__\n",
    "   \n",
    "\n",
    "    print ('Fitting {:s} model...'.format(algoname))\n",
    "    run_time = %timeit -q -o  model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    print ('... predicting')\n",
    "    y_pred      = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    print ('... scoring')\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred, average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred, average='weighted')    \n",
    "    f1        = metrics.f1_score(y_train, y_pred, average='weighted')    \n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test, average='weighted')   \n",
    "    \n",
    "    #Extracting the name of the algorithm\n",
    "    \n",
    "    return algoname, accuracy, precision, recall, f1, f1_test, run_time.best\n",
    "\n",
    "# # Instantiating base models that will be required by the adaboost regression model\n",
    "# d_tree = DecisionTreeRegressor(max_depth= 7)\n",
    "# lgbr = lgbm.LGBMRegressor()\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=10000, multi_class='ovr', solver='liblinear'),\n",
    "    MultinomialNB(),\n",
    "    KNeighborsClassifier(2),\n",
    "    LinearSVC(penalty='l2',multi_class='ovr'),\n",
    "#    SVC(kernel=\"linear\", C=0.025),\n",
    "#    SVC(gamma=2, C=1),\n",
    "    #DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7))\n",
    "]\n",
    "score=[]\n",
    "\n",
    "for algo in classifiers:\n",
    "    score.append(boost_models(algo))\n",
    "\n",
    " #Collate all scores in a table\n",
    "results = pd.DataFrame(score, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:27:44.812835Z",
     "iopub.status.busy": "2022-06-20T23:27:44.81215Z",
     "iopub.status.idle": "2022-06-20T23:27:44.826265Z",
     "shell.execute_reply": "2022-06-20T23:27:44.825041Z",
     "shell.execute_reply.started": "2022-06-20T23:27:44.812784Z"
    }
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# # fit predictor and target variable\n",
    "# x_ros, y_ros = ros.fit_resample(features, labels)\n",
    "\n",
    "# print('Original dataset shape', Counter(labels))\n",
    "# print('Resample dataset shape', Counter(y_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:28:45.521784Z",
     "iopub.status.busy": "2022-06-20T23:28:45.521366Z",
     "iopub.status.idle": "2022-06-20T23:29:02.345552Z",
     "shell.execute_reply": "2022-06-20T23:29:02.344776Z",
     "shell.execute_reply.started": "2022-06-20T23:28:45.521751Z"
    }
   },
   "outputs": [],
   "source": [
    "n_neighbors = 3 # <--- change this number to play around with how many nearest neighbours to look for.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors)\n",
    "# Fit the model \n",
    "knn.fit(X_train, y_train)\n",
    "#y_pred=nv_model.predict(X_test)\n",
    "print(f'Trainging set prediction performance is {knn.score(X_train, y_train) }')\n",
    "print(f'Testing set prediction performance is {knn.score(X_test, y_test) }')\n",
    "model_save_path = \"knn.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(knn,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:32:54.895298Z",
     "iopub.status.busy": "2022-06-20T23:32:54.894872Z",
     "iopub.status.idle": "2022-06-20T23:37:02.799775Z",
     "shell.execute_reply": "2022-06-20T23:37:02.798492Z",
     "shell.execute_reply.started": "2022-06-20T23:32:54.895261Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "ks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in ks:\n",
    "    print('Fitting KNN model with k = {:d}'.format(k))\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    run_time = %timeit -q -o knn.fit(X_train, y_train)\n",
    "    \n",
    "    # predicting\n",
    "    y_pred = knn.predict(X_train)   \n",
    "    y_pred_test = knn.predict(X_test)\n",
    "    \n",
    "    # scoring\n",
    "    accuracy  = metrics.accuracy_score(y_train, y_pred)\n",
    "    precision = metrics.precision_score(y_train, y_pred,average='weighted')\n",
    "    recall    = metrics.recall_score(y_train, y_pred,average='weighted')    \n",
    "    f1        = metrics.f1_score(y_train, y_pred,average='weighted')    \n",
    "    f1_test   = metrics.f1_score(y_test, y_pred_test,average='weighted')    \n",
    "    \n",
    "    # save the results \n",
    "    results.append([k, accuracy, precision, recall, f1, f1_test, run_time.best])\n",
    "    \n",
    "results = pd.DataFrame(results, columns=['KNN', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('K', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:38:00.655663Z",
     "iopub.status.busy": "2022-06-20T23:38:00.654501Z",
     "iopub.status.idle": "2022-06-20T23:38:00.661321Z",
     "shell.execute_reply": "2022-06-20T23:38:00.660397Z",
     "shell.execute_reply.started": "2022-06-20T23:38:00.655596Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results, columns=['KNN', 'Accuracy', 'Precision', 'Recall', 'F1 Train', 'F1 Test', 'Train Time'])\n",
    "results.set_index('KNN', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:38:08.614386Z",
     "iopub.status.busy": "2022-06-20T23:38:08.61379Z",
     "iopub.status.idle": "2022-06-20T23:38:08.628541Z",
     "shell.execute_reply": "2022-06-20T23:38:08.627453Z",
     "shell.execute_reply.started": "2022-06-20T23:38:08.614349Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:53:41.685047Z",
     "iopub.status.busy": "2022-06-19T20:53:41.684582Z",
     "iopub.status.idle": "2022-06-19T20:53:41.690613Z",
     "shell.execute_reply": "2022-06-19T20:53:41.689709Z",
     "shell.execute_reply.started": "2022-06-19T20:53:41.685013Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimators = [\n",
    "# ...     ('rf', MultinomialNB()),\n",
    "# ...     ('svr', make_pipeline(StandardScaler(),\n",
    "# ...                           LinearSVC(ax_iter=10000random_state=42)))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:53:43.326723Z",
     "iopub.status.busy": "2022-06-19T20:53:43.32592Z",
     "iopub.status.idle": "2022-06-19T20:53:43.331456Z",
     "shell.execute_reply": "2022-06-19T20:53:43.330531Z",
     "shell.execute_reply.started": "2022-06-19T20:53:43.326682Z"
    }
   },
   "outputs": [],
   "source": [
    "# clf = StackingClassifier(\n",
    "# ...     estimators=estimators, final_estimator=LogisticRegression(max_iter=10000, multi_class='ovr', solver='liblinear'),\n",
    "# )\n",
    "\n",
    "# clf.fit(X_train,y_train)\n",
    "# clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T00:09:10.157022Z",
     "iopub.status.busy": "2022-06-21T00:09:10.15655Z",
     "iopub.status.idle": "2022-06-21T00:18:16.88812Z",
     "shell.execute_reply": "2022-06-21T00:18:16.887357Z",
     "shell.execute_reply.started": "2022-06-21T00:09:10.156991Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import  mean\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "over = SMOTE(sampling_strategy={-1: 3000, 0:4000,2:5000})\n",
    "under = RandomUnderSampler(sampling_strategy={1:6000})\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, features, labels, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:18:26.885459Z",
     "iopub.status.busy": "2022-06-20T23:18:26.885039Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_model = LinearSVC(penalty='l2',multi_class='ovr')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Trainging set prediction performance is {svm_model.score(X_train, y_train) }')\n",
    "print(f'Testing set prediction performance is {svm_model.score((X_test), y_test) }')\n",
    "model_save_path = \"svm.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(svm_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:05:40.503587Z",
     "iopub.status.busy": "2022-06-20T23:05:40.50305Z",
     "iopub.status.idle": "2022-06-20T23:05:40.512318Z",
     "shell.execute_reply": "2022-06-20T23:05:40.511521Z",
     "shell.execute_reply.started": "2022-06-20T23:05:40.50354Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a baseline prediction to be used to access model performance\n",
    "acc_baseline = y_train.value_counts(normalize=True).max()\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:07:34.614481Z",
     "iopub.status.busy": "2022-06-20T23:07:34.613163Z",
     "iopub.status.idle": "2022-06-20T23:07:35.115091Z",
     "shell.execute_reply": "2022-06-20T23:07:35.113935Z",
     "shell.execute_reply.started": "2022-06-20T23:07:34.614421Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training model using Naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NV_model = MultinomialNB()\n",
    "NV_model.fit(X_train, y_train)\n",
    "\n",
    "#y_pred=nv_model.predict(X_test)\n",
    "print(f'Trainging set prediction performance is {NV_model.score(X_train, y_train) }')\n",
    "print(f'Testing set prediction performance is {NV_model.score(X_test, y_test) }')\n",
    "model_save_path = \"nb.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(NV_model,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T17:10:44.787445Z",
     "iopub.status.busy": "2022-06-18T17:10:44.787077Z",
     "iopub.status.idle": "2022-06-18T17:10:44.811678Z",
     "shell.execute_reply": "2022-06-18T17:10:44.810442Z",
     "shell.execute_reply.started": "2022-06-18T17:10:44.787416Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(); print(model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:41:01.197658Z",
     "iopub.status.busy": "2022-06-19T20:41:01.197227Z",
     "iopub.status.idle": "2022-06-19T20:41:02.001218Z",
     "shell.execute_reply": "2022-06-19T20:41:02.000076Z",
     "shell.execute_reply.started": "2022-06-19T20:41:01.197592Z"
    }
   },
   "outputs": [],
   "source": [
    "#Logistic regression model for training \n",
    "lm_model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "lm_model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Trainging set prediction performance is {lm_model.score(X_train, y_train)}')\n",
    "print(f'Testing set prediction performance is {lm_model.score(X_test,y_test) }')\n",
    "model_save_path = \"lrm.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(lm_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:49:31.995968Z",
     "iopub.status.busy": "2022-06-19T20:49:31.995495Z",
     "iopub.status.idle": "2022-06-19T20:49:32.002559Z",
     "shell.execute_reply": "2022-06-19T20:49:32.001431Z",
     "shell.execute_reply.started": "2022-06-19T20:49:31.995936Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(LogisticRegression(max_iter=10000,multi_class='ovr', solver='liblinear'),\n",
    "                            max_samples=0.5, \n",
    "                            max_features=0.5\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:49:36.826143Z",
     "iopub.status.busy": "2022-06-19T20:49:36.825782Z",
     "iopub.status.idle": "2022-06-19T20:49:48.254103Z",
     "shell.execute_reply": "2022-06-19T20:49:48.253002Z",
     "shell.execute_reply.started": "2022-06-19T20:49:36.826116Z"
    }
   },
   "outputs": [],
   "source": [
    "bagging.fit(X_train,y_train)\n",
    "model_save_path = \"bc.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(bagging,file)\n",
    "bagging.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest model for model training \n",
    "rf_model = RandomForestClassifier(n_estimators=1000,max_depth=7)\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "print(f'Trainging set prediction performance is {rf_model.score(X_train, y_train) }')\n",
    "print(f'Testing set prediction performance is {rf_model.score(X_test, y_test) }')\n",
    "model_save_path = \"rf.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(rf_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:00:22.299153Z",
     "iopub.status.busy": "2022-06-19T20:00:22.297468Z",
     "iopub.status.idle": "2022-06-19T20:08:54.761143Z",
     "shell.execute_reply": "2022-06-19T20:08:54.759906Z",
     "shell.execute_reply.started": "2022-06-19T20:00:22.299104Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Create an instance\n",
    "classifier = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                sampling_strategy='not majority',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f'Trainging set prediction performance is {classifier.score(X_train, y_train) }')\n",
    "print(f'Testing set prediction performance is {classifier.score(X_test, y_test) }')\n",
    "model_save_path = \"balbc.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(classifier,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T23:10:05.751721Z",
     "iopub.status.busy": "2022-06-16T23:10:05.750347Z",
     "iopub.status.idle": "2022-06-16T23:18:09.718328Z",
     "shell.execute_reply": "2022-06-16T23:18:09.71698Z",
     "shell.execute_reply.started": "2022-06-16T23:10:05.751653Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Dt = DecisionTreeClassifier()\n",
    "\n",
    "ada_model = AdaBoostClassifier(base_estimator=Dt)\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "ada_model.predict(X_test)\n",
    "print(f'Trainging set prediction performance is {ada_model.score(X_train, y_train) }')\n",
    "print(f'Testing set prediction performance is {ada_model.score(X_test, y_test) }')\n",
    "model_save_path = \"ada.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(ada_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:41:18.281584Z",
     "iopub.status.busy": "2022-06-19T20:41:18.281123Z",
     "iopub.status.idle": "2022-06-19T20:41:40.593008Z",
     "shell.execute_reply": "2022-06-19T20:41:40.591989Z",
     "shell.execute_reply.started": "2022-06-19T20:41:18.281553Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting up test data for submission\n",
    "df_test = pd.read_csv('/kaggle/input/edsa-climate-change-belief-analysis-2022/test.csv')\n",
    "df_test['cleaned_message'] = df_test['message'].apply(clean_title)\n",
    "df_test['model_prep_data'] = df_test['cleaned_message'].apply(model_prep_data)\n",
    "test_X = tfidf.transform(df_test.model_prep_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:47:35.401107Z",
     "iopub.status.busy": "2022-06-19T20:47:35.400678Z",
     "iopub.status.idle": "2022-06-19T20:47:35.898678Z",
     "shell.execute_reply": "2022-06-19T20:47:35.897285Z",
     "shell.execute_reply.started": "2022-06-19T20:47:35.401074Z"
    }
   },
   "outputs": [],
   "source": [
    "#Making prediction for submission\n",
    "new_pred = clf.predict(test_X)\n",
    "df_test['sentiment'] = new_pred\n",
    "df_test.rename(columns={'pred':'sentiment'},inplace=True)\n",
    "sub = df_test[['tweetid','sentiment']]\n",
    "sub = sub.set_index('tweetid')\n",
    "#sub.to_csv('Submission17.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub.to_csv('Submission12.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
